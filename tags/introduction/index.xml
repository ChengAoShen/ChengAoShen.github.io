<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction | ChengAo Shen</title>
    <link>https://chengaoshen.com/tags/introduction/</link>
      <atom:link href="https://chengaoshen.com/tags/introduction/index.xml" rel="self" type="application/rss+xml" />
    <description>Introduction</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 15 Jul 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://chengaoshen.com/media/icon_hu_5e76b9ed60a85934.png</url>
      <title>Introduction</title>
      <link>https://chengaoshen.com/tags/introduction/</link>
    </image>
    
    <item>
      <title>‚öΩÔ∏èIntroduction to Prompt Engineering</title>
      <link>https://chengaoshen.com/blogs/introduction-to-prompt-engineering/</link>
      <pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/blogs/introduction-to-prompt-engineering/</guid>
      <description>&lt;h2 id=&#34;basic-knowledge&#34;&gt;Basic Knowledge&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Prompt engineering&lt;/strong&gt; is a relatively new discipline for developing and optimizing prompts to efficiently use large lange models (LLMs) for a wide variety of applications and research topics. Researchers use prompt engineering to improve the safety and the capacity of LLMs on a wide range of common and complex tasks such as question answering and arithmetic reasoning. Developers use prompt engineering to design robust and effective prompting techniques that interface with LLMs and other tools.&lt;/p&gt;
&lt;p&gt;When designing and testing prompts, we typically interact with the LLMs via an API. Some paprameters will influence the performance of the model, below are some common settings that will come across when using LLMs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Temperature - This parameter controls the degree of randomness in the model&amp;rsquo;s output. A higher temperature will result in more random outputs, while a lower temperature will result in more repetitive outputs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Top P - This parameter controls the sampling strategy used by the model when generating multiple possible outputs. A higher value of Top P will result in more diverse outputs, while a lower value will result in more repetitive outputs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The general recommendation is to alter temperature or Top P but not both.&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Max Length - This parameter controls the number of tokens the model generates in its output. Using a typical max length will help to prevent long or irrelevant responses and control costs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop Sequences - This parameter is a string that stops the model from generating tokens. This is another way to control the length and structure of the model&amp;rsquo;s response.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Frequency Penalty - This parameter will add a penalty to the same tokens in the model&amp;rsquo;s output when it appears, which can help to prevent a repetition of this word. Higher values of frequency penalty will reduce the repetition of tokens in the model&amp;rsquo;s output.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Presence Penalty - This parameter will set a penalty to the appeared word (Not add more penalty when the word appears more than once), which can reduce the repetition of the same word in the model&amp;rsquo;s output. Higher values of presence penalty will reduce the repetition of the same word in the model&amp;rsquo;s output.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;prompts&#34;&gt;Prompts&lt;/h2&gt;
&lt;h3 id=&#34;what-is-a-prompt&#34;&gt;What is a prompt?&lt;/h3&gt;
&lt;p&gt;Prompts are used to guide the model to generate the correct outputs. A prompt can contain information like the &lt;strong&gt;instruction&lt;/strong&gt; or &lt;strong&gt;question&lt;/strong&gt; you are passing to the model and include other details such as &lt;strong&gt;context&lt;/strong&gt;, &lt;strong&gt;inputs&lt;/strong&gt;, or &lt;strong&gt;examples&lt;/strong&gt;. You can use these elements to instruct the model more effectively to improve the quality of results.&lt;/p&gt;
&lt;p&gt;When using GPT3.5 or GPT4, the prompt can be structured in three different roles: &lt;strong&gt;system&lt;/strong&gt;, &lt;strong&gt;user&lt;/strong&gt;, and &lt;strong&gt;assistant&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System - Setting the behavior, character, and background of the models.&lt;/li&gt;
&lt;li&gt;User - Asking the question or providing the context.&lt;/li&gt;
&lt;li&gt;Assistant - Automatically generated by the System and user prompts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Normally we only use user prompts to interact with the model.&lt;/p&gt;
&lt;h3 id=&#34;prompt-format&#34;&gt;Prompt Format&lt;/h3&gt;
&lt;p&gt;The prompt can be formatted with different structures divided into zero-shot or few-shot. Zero-shot prompting means it can directly prompt the model for a response without any examples or demonstrations of the task. One typical zero-shot example is the Question/Answering (QA) format:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Q: &amp;lt;Question&amp;gt;?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A: &amp;lt;Answer&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Q: &amp;lt;Question&amp;gt;?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A: &amp;lt;Answer&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Q: &amp;lt;Question&amp;gt;?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A: 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Different formats of prompts can be used in various tasks, such as classification prompts:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;This is awesome! // Positive
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;This is bad! // Negative
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Wow, that movie was rad! // Positive
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;What a horrible show! //
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Negative
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This format is a few-shot that can enable in-context learning.&lt;/p&gt;
&lt;h3 id=&#34;prompt-elements&#34;&gt;Prompt Elements&lt;/h3&gt;
&lt;p&gt;One typical prompt often contains any of the following elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Instruction&lt;/strong&gt; - a specific task or instruction you want the model to perform&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Context&lt;/strong&gt; - external information or additional context that can steer the model to better responses&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Input Data&lt;/strong&gt; - the input or question that we are interested in finding a response for&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output Indicator&lt;/strong&gt; - the type or format of the output&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;designing-tips&#34;&gt;Designing Tips&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Start Simple&lt;/p&gt;
&lt;p&gt;In the beginning, use simple models and prompts, and iterate continuously to meet the requirements.&lt;/p&gt;
&lt;p&gt;When there is a large task, try to break it down into multiple subtasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Obvious Instruction&lt;/p&gt;
&lt;p&gt;Giving clear instructions when designing the prompt can help to improve the output performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Specificity&lt;/p&gt;
&lt;p&gt;More detailed requirements can help the model output meet the requirements.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Extract the name of places in the following text. 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Desired format:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Place: &amp;lt;comma_separated_list_of_places&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Input: &amp;#34;Although these developments are encouraging to researchers, much is still a mystery. ‚ÄúWe often have a black box between the brain and the effect we see in the periphery,‚Äù says Henrique Veiga-Fernandes, a neuroimmunologist at the Champalimaud Centre for the Unknown in Lisbon. ‚ÄúIf we want to use it in the therapeutic context, we actually need to understand the mechanism.&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Avoid Imprecisseness&lt;/p&gt;
&lt;p&gt;Use the most straightforward language to communicate.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Use 2-3 sentences to explain the concept of prompt engineering to a high school student.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Say Do What&lt;/p&gt;
&lt;p&gt;Avoid saying what not to do but say what to do instead&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ü§óIntroduction to Generative Models</title>
      <link>https://chengaoshen.com/blogs/introduction-to-generative-models/</link>
      <pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/blogs/introduction-to-generative-models/</guid>
      <description>&lt;p&gt;Generative Models are part of unsupervised learning models that can learned from the datasets without any labels. Unlike other unsupervised models to manipulate, denoise, interpolate between, or compress examples, generative models focus on generating plausible new samples having similar properties to the dataset.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;figure&#34;&gt;
  &lt;img class=&#34;img&#34; src=&#34;https://raw.githubusercontent.com/ChengAoShen/Image-Hosting/main/images/image-20231025211322464.png&#34; alt=&#34;Taxonomy of unsupervised learning models&#34;&gt;
  &lt;figcaption style=&#34;text-align: center;&#34;&gt;Taxonomy of unsupervised learning models&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Latent variable models&lt;/strong&gt;: mapping the data examples $\mathbf{x}$ to unseen latent variables $\mathbf{z}$ which can capture the underlying structure in the dataset.&lt;/p&gt;
&lt;p&gt;In this essay, we will introduce the categories of generative models, discuss their properties, and talk about how to measure them.&lt;/p&gt;
&lt;h2 id=&#34;what-are-probabilistic-models&#34;&gt;What are probabilistic models?&lt;/h2&gt;
&lt;p&gt;Before we dive into the typical forms of generative models, we should understand two major categories of them.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Direct generative models, such as generative adversarial models, aim to provide a mechanism for generating samples similar to observed data $\{\mathbf{x}_i\}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$
  L[\phi]=-\sum_{i=1}^{I}\mathrm{log}[Pr(\mathbf{x}_i|\phi)]
  $$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is an image to describe the training process of the two models.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;figure&#34;&gt;
  &lt;img class=&#34;img&#34; src=&#34;https://raw.githubusercontent.com/ChengAoShen/Image-Hosting/main/images/Training%20of%20generative%20models.png&#34; alt=&#34;Training of generative models&#34;&gt;
  &lt;figcaption style=&#34;text-align: center;&#34;&gt;Training of generative models&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;properties-of-generative-models&#34;&gt;Properties of Generative Models&lt;/h2&gt;
&lt;p&gt;There are several properties that Generative Models need to have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Efficient sampling: using less computational consumption.&lt;/li&gt;
&lt;li&gt;High-quality sampling: output is indistinguishable from train data&lt;/li&gt;
&lt;li&gt;Coverage: samples should represent the entire training distribution&lt;/li&gt;
&lt;li&gt;Well-behaved latent space: change in latent space will perform in data similarly.&lt;/li&gt;
&lt;li&gt;Efficient likelihood computation: able to calculate the probability of new examples efficiently.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It‚Äôs hard for only one type of Generative Model to obtain all properties, following is a table to describe some generative model‚Äôs features:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Model&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Probabilistic&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Efficient&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Sample quality&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Coverage&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Well-behaved latent space&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Disentangled latent space&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Efficient likelihood&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;GANs&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚ùî&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;\&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;Flows&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚ùî&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚ùî&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;VAEs&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚ùî&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚ùî&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;Diffusion&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úîÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚ùî&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;‚úñÔ∏è&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;performance-measurement&#34;&gt;Performance Measurement&lt;/h2&gt;
&lt;p&gt;To measure the performance of generative models, some metrics are proposed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inception score (IS)&lt;/strong&gt;: This metric is used in image generative models which trained on the ImageNet dataset. There are two criteria to design it. First, each generated image $\mathbf{x}^*$ should look like only one class in the ImageNet dataset which has 1000 possible classes. Second, the probability for each class in generated images should be equal.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;figure&#34;&gt;
  &lt;img class=&#34;img&#34; src=&#34;https://raw.githubusercontent.com/ChengAoShen/Image-Hosting/main/images/image-20231026144638161.png&#34; alt=&#34;Inception score&#34;&gt;
  &lt;figcaption style=&#34;text-align: center;&#34;&gt;Inception score&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;
$$
IS=\mathrm{exp}\bigg[\frac{1}{I}\sum_{i=1}^{I}D_{KL}\big[Pr(y_i|\mathbf{x}_i^*)||Pr(y)\big]\bigg]
$$$$
Pr(y)=\frac{1}{I}\sum_{i=1}^{I}Pr(y_i|\mathbf{x}_i^*)
$$&lt;p&gt;
&lt;strong&gt;Fr√©chet inception distance&lt;/strong&gt;: To decrease the reliance on the ImageNet dataset and characterize either distribution, the Fr√©chet inception distance is estimated.&lt;/p&gt;
&lt;p&gt;First, use the inception model accepting both observed and generated images as input to produce $1\times 2048$ feature vector. And, because the images follow the normal distribution which can be defined by mean and variance, we can use them to calculate the distance between real and generated images.&lt;/p&gt;
$$
FID(x,g)=||\mu_x-\mu_g||_2^2+Tr\big(\Sigma_x+\Sigma_g-2(\Sigma_x\Sigma_g)^{0.5}\big)
$$&lt;p&gt;
Where $x,g$ present real and generated images, $\mu$ is the mean and $\Sigma$ is the covariance.&lt;/p&gt;
&lt;p&gt;However, this metric uses the inception network output to calculate, which will more focus on the semantic information.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Manifold precision/recall&lt;/strong&gt;: To disentangle the realism of the samples and their diversity, we consider the overlap between the data manifold and the model manifold.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Precision is the fraction of &lt;strong&gt;model samples&lt;/strong&gt; that fall into the &lt;strong&gt;data manifold&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Recall is the fraction of &lt;strong&gt;data examples&lt;/strong&gt; that fall within the &lt;strong&gt;model manifold&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;p&gt;[1] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, ‚ÄòRethinking the Inception Architecture for Computer Vision‚Äô, in &lt;em&gt;Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)&lt;/em&gt;, 2016.&lt;/p&gt;
&lt;p&gt;[2] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter, ‚ÄòGANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium‚Äô, in &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt;, 2017, vol. 30.&lt;/p&gt;
&lt;p&gt;[3] S. J. D. Prince, &lt;em&gt;Understanding Deep Learning&lt;/em&gt;. MIT Press, 2023.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
