<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hanghang Tong on ChengAo Shen</title>
    <link>https://chengaoshen.com/authors/hanghang-tong/</link>
    <description>Recent content in Hanghang Tong on ChengAo Shen</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 02 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://chengaoshen.com/authors/hanghang-tong/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?</title>
      <link>https://chengaoshen.com/en/publications/av4ts/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/en/publications/av4ts/</guid>
      <description>&lt;p&gt;Abstract: Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truely useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Harnessing Vision Models for Time Series Analysis: A Survey</title>
      <link>https://chengaoshen.com/en/publications/v4ts_survey/</link>
      <pubDate>Tue, 15 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/en/publications/v4ts_survey/</guid>
      <description>&lt;p&gt;Abstract: Time series analysis has witnessed the inspiring development from traditional autoregressive models, deep learning models, to recent Transformers and Large Language Models (LLMs). Efforts in leveraging vision models for time series analysis have also been made along the way but are less visible to the community due to the predominant research on sequence modeling in this domain. However, the discrepancy between continuous time series and the discrete token space of LLMs, and the challenges in explicitly modeling the correlations of variates in multivariate time series have shifted some research attentions to the equally successful Large Vision Models (LVMs) and Vision Language Models (VLMs). To fill the blank in the existing literature, this survey discusses the advantages of vision models over LLMs in time series analysis. It provides a comprehensive and in-depth overview of the existing methods, with dual views of detailed taxonomy that answer the key research questions including how to encode time series as images and how to model the imaged time series for various tasks. Additionally, we address the challenges in the pre- and post-processing steps involved in this framework and outline future directions to further advance time series analysis with vision models.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
