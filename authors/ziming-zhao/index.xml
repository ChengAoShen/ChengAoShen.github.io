<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ziming Zhao on ChengAo Shen</title>
    <link>https://chengaoshen.com/authors/ziming-zhao/</link>
    <description>Recent content in Ziming Zhao on ChengAo Shen</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 12 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://chengaoshen.com/authors/ziming-zhao/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SVTime: Small Time Series Forecasting Models Informed by &#34;Physics&#34; of Large Vision Model Forecasters</title>
      <link>https://chengaoshen.com/en/publications/svtime/</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/en/publications/svtime/</guid>
      <description>&lt;p&gt;Abstract: Time series AI is crucial for analyzing dynamic web content, driving a surge of pre-trained large models known for their strong knowledge encoding and transfer capabilities across diverse tasks. However, given their energy-intensive training, inference, and hardware demands, using large models as a one-fits-all solution raises serious concerns about carbon footprint and sustainability. For a specific task, a compact yet specialized, high-performing model may be more practical and affordable, especially for resource-constrained users such as small businesses. This motivates the question: Can we build cost-effective lightweight models with large-model-like performance on core tasks such as forecasting? This paper addresses this question by introducing SVTime, a novel Small model inspired by large Vision model (LVM) forecasters for long-term Time series forecasting (LTSF). Recently, LVMs have been shown as powerful tools for LTSF. We identify a set of key inductive biases of LVM forecasters &amp;ndash; analogous to the &amp;ldquo;physics&amp;rdquo; governing their behaviors in LTSF &amp;ndash; and design small models that encode these biases through meticulously crafted linear layers and constraint functions. Across 21 baselines spanning lightweight, complex, and pre-trained large models on 8 benchmark datasets, SVTime outperforms state-of-the-art (SOTA) lightweight models and rivals large models with 10^3 fewer parameters than LVMs, while enabling efficient training and inference in low-resource settings.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?</title>
      <link>https://chengaoshen.com/en/publications/av4ts/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/en/publications/av4ts/</guid>
      <description>&lt;p&gt;Abstract: Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truely useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multi-Modal View Enhanced Large Vision Models for Long-Term Time Series Forecasting</title>
      <link>https://chengaoshen.com/en/publications/dmmv/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/en/publications/dmmv/</guid>
      <description>&lt;p&gt;Abstract: Time series, typically represented as numerical sequences, can also be transformed into images and texts, offering multi-modal views (MMVs) of the same underlying signal. These MMVs can reveal complementary patterns and enable the use of powerful pre-trained large models, such as large vision models (LVMs), for long-term time series forecasting (LTSF). However, as we identified in this work, applying LVMs to LTSF poses an inductive bias towards &amp;ldquo;forecasting periods&amp;rdquo;. To harness this bias, we propose DMMV, a novel decomposition-based multi-modal view framework that leverages trend-seasonal decomposition and a novel backcast residual based adaptive decomposition to integrate MMVs for LTSF. Comparative evaluations against 14 state-of-the-art (SOTA) models across diverse datasets show that DMMV outperforms single-view and existing multi-modal baselines, achieving the best mean squared error (MSE) on 6 out of 8 benchmark datasets.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Harnessing Vision Models for Time Series Analysis: A Survey</title>
      <link>https://chengaoshen.com/en/publications/v4ts_survey/</link>
      <pubDate>Tue, 15 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://chengaoshen.com/en/publications/v4ts_survey/</guid>
      <description>&lt;p&gt;Abstract: Time series analysis has witnessed the inspiring development from traditional autoregressive models, deep learning models, to recent Transformers and Large Language Models (LLMs). Efforts in leveraging vision models for time series analysis have also been made along the way but are less visible to the community due to the predominant research on sequence modeling in this domain. However, the discrepancy between continuous time series and the discrete token space of LLMs, and the challenges in explicitly modeling the correlations of variates in multivariate time series have shifted some research attentions to the equally successful Large Vision Models (LVMs) and Vision Language Models (VLMs). To fill the blank in the existing literature, this survey discusses the advantages of vision models over LLMs in time series analysis. It provides a comprehensive and in-depth overview of the existing methods, with dual views of detailed taxonomy that answer the key research questions including how to encode time series as images and how to model the imaged time series for various tasks. Additionally, we address the challenges in the pre- and post-processing steps involved in this framework and outline future directions to further advance time series analysis with vision models.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
