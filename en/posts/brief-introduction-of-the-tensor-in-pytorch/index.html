<!DOCTYPE html>
<html lang="en">

<head>
  <title>
  ⚕️Brief introduction of the Tensor in PyTorch · ChengAo Shen
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="ChengAo Shen">
<meta name="description" content="Tensor is a specialized data structure that is very similar to arrays and matrices. We can use it to encode the input and output of the model. Tensors can run on GPUs and other hardware.

  Initializing a Tensors
  
    
    Link to heading
  

Tensors can be initialized in various ways,
# Import the library
import torch

# Directly from data
data=[[1,2],
      [2,3]]
t_data = torch.tensor(data)

# From Numpy
import numpy as np
np_data = np.array(data)
t_np =  torch.from_numpy(np_data)

# From other tensors
# In this way, it will retains same properties
t_ones = torch.ones_like(t_data) 
# override the datatype
t_random = torch.rand_like(t_data,dtype=torch.float) 

# With static shape
shape = (2,3,)
rand_t = torch.rand(shape)
ones_t = torch.ones(shape)
zeros_t = torch.zeros(shape)

Careful: If you initialize the tensors from Numpy, they will share the same underlying memory, which means that if changing the numpy array, the tensor will change too.">
<meta name="keywords" content="ChengAo Shen, homepage,university of houston, personal blog">



  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="⚕️Brief introduction of the Tensor in PyTorch">
  <meta name="twitter:description" content="Tensor is a specialized data structure that is very similar to arrays and matrices. We can use it to encode the input and output of the model. Tensors can run on GPUs and other hardware.
Initializing a Tensors Link to heading Tensors can be initialized in various ways,
# Import the library import torch # Directly from data data=[[1,2], [2,3]] t_data = torch.tensor(data) # From Numpy import numpy as np np_data = np.array(data) t_np = torch.from_numpy(np_data) # From other tensors # In this way, it will retains same properties t_ones = torch.ones_like(t_data) # override the datatype t_random = torch.rand_like(t_data,dtype=torch.float) # With static shape shape = (2,3,) rand_t = torch.rand(shape) ones_t = torch.ones(shape) zeros_t = torch.zeros(shape) Careful: If you initialize the tensors from Numpy, they will share the same underlying memory, which means that if changing the numpy array, the tensor will change too.">

<meta property="og:url" content="https://chengaoshen.com/en/posts/brief-introduction-of-the-tensor-in-pytorch/">
  <meta property="og:site_name" content="ChengAo Shen">
  <meta property="og:title" content="⚕️Brief introduction of the Tensor in PyTorch">
  <meta property="og:description" content="Tensor is a specialized data structure that is very similar to arrays and matrices. We can use it to encode the input and output of the model. Tensors can run on GPUs and other hardware.
Initializing a Tensors Link to heading Tensors can be initialized in various ways,
# Import the library import torch # Directly from data data=[[1,2], [2,3]] t_data = torch.tensor(data) # From Numpy import numpy as np np_data = np.array(data) t_np = torch.from_numpy(np_data) # From other tensors # In this way, it will retains same properties t_ones = torch.ones_like(t_data) # override the datatype t_random = torch.rand_like(t_data,dtype=torch.float) # With static shape shape = (2,3,) rand_t = torch.rand(shape) ones_t = torch.ones(shape) zeros_t = torch.zeros(shape) Careful: If you initialize the tensors from Numpy, they will share the same underlying memory, which means that if changing the numpy array, the tensor will change too.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="en">
    <meta property="article:published_time" content="2022-10-26T00:00:00+00:00">
    <meta property="article:modified_time" content="2022-10-26T00:00:00+00:00">




<link rel="canonical" href="https://chengaoshen.com/en/posts/brief-introduction-of-the-tensor-in-pytorch/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.2cd2ba040eaadea1390f8199e24bd994fabd69b5a7034b43fc2440c58fd09808.css" integrity="sha256-LNK6BA6q3qE5D4GZ4kvZlPq9abWnA0tD/CRAxY/QmAg=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">

<link rel="icon" type="image/png" href="/images/favicon.png">








</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="https://chengaoshen.com/">
      ChengAo Shen
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/en/posts/">Posts</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/en/news/">News</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/en/publications/">Publications</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/en/about/">About Me</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container page">
  <article>
    <header>
      <h1 class="title">
        <a class="title-link" href="https://chengaoshen.com/en/posts/brief-introduction-of-the-tensor-in-pytorch/">
          ⚕️Brief introduction of the Tensor in PyTorch
        </a>
      </h1>
    </header>

    <p>Tensor is a specialized data structure that is very similar to arrays and matrices. We can use it to encode the input and output of the model. Tensors can run on GPUs and other hardware.</p>
<h2 id="initializing-a-tensors">
  Initializing a Tensors
  <a class="heading-link" href="#initializing-a-tensors">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>Tensors can be initialized in various ways,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Import the library</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Directly from data</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">      <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">t_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># From Numpy</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="n">np_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">t_np</span> <span class="o">=</span>  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># From other tensors</span>
</span></span><span class="line"><span class="cl"><span class="c1"># In this way, it will retains same properties</span>
</span></span><span class="line"><span class="cl"><span class="n">t_ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">t_data</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="c1"># override the datatype</span>
</span></span><span class="line"><span class="cl"><span class="n">t_random</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">t_data</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># With static shape</span>
</span></span><span class="line"><span class="cl"><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,)</span>
</span></span><span class="line"><span class="cl"><span class="n">rand_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ones_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">zeros_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><blockquote>
<p><strong>Careful</strong>: If you initialize the tensors from Numpy, they will share the same underlying memory, which means that if changing the numpy array, the tensor will change too.</p></blockquote>
<h2 id="attributes-of-a-tensor">
  Attributes of a Tensor
  <a class="heading-link" href="#attributes-of-a-tensor">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>We can get some attributes of a tensor by code followed</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">t_data</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># Get the shape of the tensor</span>
</span></span><span class="line"><span class="cl"><span class="n">t_data</span><span class="o">.</span><span class="n">dtype</span> <span class="c1"># Get the dtype</span>
</span></span><span class="line"><span class="cl"><span class="n">t_data</span><span class="o">.</span><span class="n">device</span> <span class="c1">#  return the device(CPU or GPU) for this tensor</span>
</span></span></code></pre></div><h2 id="operation-on-tensor">
  Operation on Tensor
  <a class="heading-link" href="#operation-on-tensor">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>There are over 100 operations for tensors, including arithmetic, linear algebra, matrix manipulation, and sampling. Each of these operations can be run on GUP, but by default it&rsquo;s in CPU, we can move by  <code>.to</code>  like the following:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">t_data</span> <span class="o">=</span> <span class="n">t_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>Here are some common operations:</p>
<ol>
<li>
<p>Indexing and Slicing</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">t_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># get the first row of tensor</span>
</span></span><span class="line"><span class="cl"><span class="n">t_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># get the first column of tensor</span>
</span></span><span class="line"><span class="cl"><span class="n">t_data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># get the last column of tensor</span>
</span></span><span class="line"><span class="cl"><span class="n">t_data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span> <span class="c1"># change secound column to zero</span>
</span></span></code></pre></div></li>
<li>
<p>Joining tensors</p>
<p>we can concatenate a sequence of tensors by a given dimension <code>torch.cat([t_data,t_data],dim=1)</code></p>
</li>
<li>
<p>Arithmetic operations</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># computes the matrix multiplication</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span> <span class="o">=</span> <span class="n">t_data</span> <span class="o">@</span> <span class="n">t_data</span><span class="o">.</span><span class="n">T</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span> <span class="o">=</span> <span class="n">t_data</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_data</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_data</span><span class="p">,</span><span class="n">t_data</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># computes the element-wise product</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span> <span class="o">=</span> <span class="n">t_data</span> <span class="o">*</span> <span class="n">t_data</span><span class="o">.</span><span class="n">T</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span> <span class="o">=</span> <span class="n">t_data</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">t_data</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">t_data</span><span class="p">,</span><span class="n">t_data</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">)</span>
</span></span></code></pre></div></li>
<li>
<p>Single-element tensors</p>
<p>If you have one-element tensor, can convert it to python value by <code>t_data.item()</code></p>
</li>
<li>
<p>In place operations</p>
<p>Sometime we would like to change tensors them self, instead of return an answer. In order to do this we can add  <code>_</code> behind the function.</p>
<p>For example:<code>t_data.add_(5)</code>will add five for all element it self.</p>
</li>
</ol>

  </article>
</section>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body,
      {
        delimiters: [
          {left: '$$', right: '$$', display:true},
          {left: '$', right: '$', display:false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
      }
    );"></script>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2024 -
    
    2025
     ChengAo Shen 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>
</html>
